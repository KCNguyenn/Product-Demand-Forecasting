{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Product Demand - Code to run forecast automatically\n",
    "This notebook gives code to run the forecast automatically. <br/>\n",
    "\n",
    "Several notes: <br/>\n",
    "- The logic behind the code can be found in notebook name \"Historical Product Demand (Analysis + Model)\". <br/>\n",
    "- There is hardcode to remove data before Sep 2011. The reason is that the provided dataset seems to have several flaws because there were no data provided for several months in 2011 (Feb, Mar, Apr, Jul, and Aug). Usually, forecast user just extract historical data from system and thus, can't have those months missed for all products. <br/>\n",
    "- There is code to set current_date = 2017/01/10. Because the latest data is on 2017/01/09, I suppose that it is currently Jan, 2017 and the forecast user wants to get forecast from March onwards (as stated in the objective of the dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packagse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import attrgetter\n",
    "#pip install pmdarima\n",
    "from pmdarima.arima import auto_arima\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_run(data,fcastperiods):\n",
    "    \"Format data\"\n",
    "    data['Date'] = pd.to_datetime(data['Date']) ## Format Date to datetime\n",
    "    data['Order_Demand'] = data['Order_Demand'].str.replace('(','-') # Format Order_Demand to numeric\n",
    "    data['Order_Demand'] = data['Order_Demand'].str.replace(')','') \n",
    "    data['Order_Demand'] = pd.to_numeric(data['Order_Demand'])\n",
    "    data = data.drop(columns=['Warehouse','Product_Category']) # Drop warehouse and category columns\n",
    "    data = data.sort_values('Date').reset_index().drop('index',axis=1) # Sort data by period\n",
    "    \n",
    "    \"Remove NA\"\n",
    "    data = data.dropna(how='any',axis=0)\n",
    "    \n",
    "    \"Remove returns values\"\n",
    "    data['Abs_Demand'] = abs(data['Order_Demand']) # Create column with absolute values of order_demand column\n",
    "    data_nodup = data.drop_duplicates(subset = ['Product_Code','Date','Abs_Demand'], keep = False) # Re duplicates\n",
    "    duplicates = data.iloc[~data.index.isin(data_nodup.index)] # Extract removed duplicates to df and aggregate\n",
    "    duplicates = pd.pivot_table(duplicates, values='Order_Demand',index=['Product_Code','Date'],aggfunc=np.sum\n",
    "                           ).reset_index()\n",
    "    duplicates = duplicates.loc[duplicates['Order_Demand']>0]\n",
    "    data = data.drop_duplicates(subset = ['Product_Code','Date','Abs_Demand'], keep = False) # Re neg values\n",
    "    data = data.drop('Abs_Demand',axis=1)\n",
    "    data = data.loc[data['Order_Demand']>0]\n",
    "    data = pd.concat([data,duplicates], ignore_index = True) # Add duplicates table back to data\n",
    "    \n",
    "    \"Aggregate data by month\"\n",
    "    data['Date'] = data['Date'].dt.to_period('M')\n",
    "    data = data.rename(columns = {\"Date\": 'Period'})\n",
    "    data = data.groupby(['Product_Code','Period'])['Order_Demand'].sum().reset_index().sort_values('Period'\n",
    "            ).reset_index().drop('index',axis=1)\n",
    "    \n",
    "    \"Remove data before Sep 2016 - Reason explained in description\" \n",
    "    data = data.loc[data['Period'] > '2011-08']\n",
    "    \n",
    "    \"Remove products ineligible for forecasting\"\n",
    "    current_date = pd.to_datetime(\"2017-01-10\") # replace python code to get today's date\n",
    "    current_date = current_date.to_period('M')\n",
    "    data = data.loc[data['Period']<current_date] # remove data of current month\n",
    "    \n",
    "    latest_datamonth = data.groupby('Product_Code')['Period'].max().reset_index() # remove stopped products\n",
    "    latest_month = data['Period'].max()-12\n",
    "    stopped_month = latest_datamonth.loc[latest_datamonth['Period'] <= latest_month] # to get stopped product list\n",
    "    stopped_products = data.loc[data['Product_Code'].isin(stopped_month['Product_Code'])]\n",
    "    stopped_products_list = set(stopped_products['Product_Code'].tolist())\n",
    "    \n",
    "    latest_datamonth = latest_datamonth.loc[latest_datamonth['Period'] > latest_month] # remove stopped products     \n",
    "    data = data.loc[data['Product_Code'].isin(latest_datamonth['Product_Code'])]      \n",
    "    \n",
    "    duration_data = data.groupby('Product_Code').agg({'Period': ['min', 'max']}).reset_index() # re new products\n",
    "    duration_data['Duration'] = (duration_data[('Period', 'max')] - duration_data[('Period', 'min')]\n",
    "                            ).apply(attrgetter('n')) + 1\n",
    "    new_month = duration_data.loc[duration_data['Duration'] <= 24 ]\n",
    "    new_products = data.loc[data['Product_Code'].isin(new_month['Product_Code'])]\n",
    "    new_products_list = set(new_products['Product_Code'].tolist())\n",
    "    \n",
    "    duration_data = duration_data.loc[duration_data['Duration'] > 24 ]\n",
    "    data = data.loc[data['Product_Code'].isin(duration_data['Product_Code'])]\n",
    "    \n",
    "    \"Construct time series in a columnar format\"\n",
    "    data = pd.pivot_table(data, values = 'Order_Demand', index = 'Period', columns = 'Product_Code',\n",
    "                          aggfunc=np.sum).reset_index().rename_axis(\"\", axis=\"columns\")\n",
    "    data = data.fillna(0)\n",
    "    data = data.set_index('Period')\n",
    "    \n",
    "    \"Sample data for demonstration\"\n",
    "    data = data[['Product_0002','Product_0138','Product_0597','Product_0875','Product_2066',\n",
    "               'Product_2091','Product_2127','Product_2165']]\n",
    "    \n",
    "    \"\"\"Build models\"\"\"\n",
    "    def train_test(data):\n",
    "        myList = data.tolist() \n",
    "        i = myList.index(next(filter(lambda x: x!=0, myList)))\n",
    "        data = data.iloc[i:,] \n",
    "        train = data[:int(0.7*(len(data)))]\n",
    "        test = data[int(0.7*len(data)):] \n",
    "        return train, test\n",
    "\n",
    "    start = data.index.tolist()[-1] + 3\n",
    "    full_period = [start + x for x in range(0,fcastperiods)]\n",
    "    \n",
    "    \"ARIMA Model\"\n",
    "    Arima = ['Arima']\n",
    "    ArimaFcastPerf = pd.DataFrame({'Models': Arima})\n",
    "    ArimaData = pd.DataFrame({'Period': full_period, 'Model': 'Arima'})\n",
    "\n",
    "    def arimafcast(data):\n",
    "        for i in data.columns:\n",
    "            try:\n",
    "                train, test = train_test(data[i])\n",
    "                model = auto_arima(train, start_p=0, start_q=0, m=1, trace=True, \n",
    "                                   error_action='ignore', suppress_warnings=True)\n",
    "                model.fit(train)\n",
    "                pred = np.round(model.predict(n_periods=len(test)+3+fcastperiods-1))\n",
    "                ArimaFcastPerf[i] = sqrt(mean_squared_error(test,pred[:-fcastperiods-2]))\n",
    "                ArimaData[i] = pred[-fcastperiods:]\n",
    "            except:\n",
    "                ArimaFcastPerf[i] = np.nan\n",
    "                ArimaData[i] = np.nan\n",
    "        return ArimaFcastPerf, ArimaData\n",
    "    arimafcast(data)   \n",
    "    \n",
    "    \"Simple Exponential Smoothing\"\n",
    "    SES = ['SES']\n",
    "    SESFcastPerf = pd.DataFrame({'Models': SES})\n",
    "    SESData = pd.DataFrame({'Period': full_period, 'Model': 'SES'})\n",
    "\n",
    "    def sesfcast(data):\n",
    "        for i in data.columns:\n",
    "            try:\n",
    "                train, test = train_test(data[i])\n",
    "                model = SimpleExpSmoothing(train).fit()\n",
    "                pred = np.round(model.forecast(len(test)+3+fcastperiods-1))\n",
    "                SESFcastPerf[i] = sqrt(mean_squared_error(test,pred[:-fcastperiods-2]))\n",
    "                SESData[i] = pred[-fcastperiods:].tolist()\n",
    "            except:\n",
    "                SESFcastPerf[i] = np.nan\n",
    "                SESData[i] = np.nan\n",
    "        return SESFcastPerf, SESData\n",
    "    sesfcast(data)\n",
    "    \n",
    "    \"Double Exponential Smoothing\"\n",
    "    DES = ['DES']\n",
    "    DESFcastPerf = pd.DataFrame({'Models': DES})\n",
    "    DESData = pd.DataFrame({'Period': full_period, 'Model': 'DES'})\n",
    "\n",
    "    def desfcast(data):\n",
    "        for i in data.columns:\n",
    "            try:\n",
    "                train, test = train_test(data[i])\n",
    "                if train.min() != 0: #Double & Triple Exponential Smoothing only applies to positive data values\n",
    "                    model = ExponentialSmoothing(train, trend='add', seasonal=None, damped=True\n",
    "                                                ).fit(optimized=True,use_boxcox=True)\n",
    "                    pred = np.round(model.forecast(len(test)+3+fcastperiods-1))\n",
    "                    DESFcastPerf[i] = sqrt(mean_squared_error(test,pred[:-fcastperiods-2]))\n",
    "                    DESData[i] = pred[-fcastperiods:].tolist()\n",
    "                else:\n",
    "                    DESFcastPerf[i] = np.nan\n",
    "                    DESData[i] = np.nan  \n",
    "            except:\n",
    "                DESFcastPerf[i] = np.nan\n",
    "                DESData[i] = np.nan\n",
    "        return DESFcastPerf, DESData\n",
    "    desfcast(data)\n",
    "    \n",
    "    \"Triple Exponential Smoothing\"\n",
    "    TES = ['TES']\n",
    "    TESFcastPerf = pd.DataFrame({'Models': TES})\n",
    "    TESData = pd.DataFrame({'Period': full_period, 'Model': 'TES'})\n",
    "\n",
    "    def tesfcast(data):\n",
    "        for i in data.columns:\n",
    "            try:\n",
    "                train, test = train_test(data[i])\n",
    "                if train.min() != 0: \n",
    "                    model = ExponentialSmoothing(train, seasonal_periods=12, \n",
    "                                                 trend='add', seasonal='mul', damped=True\n",
    "                                                ).fit(optimized=True,use_boxcox=True)\n",
    "                    pred = np.round(model.forecast(len(test)+3+fcastperiods-1))\n",
    "                    TESFcastPerf[i] = sqrt(mean_squared_error(test,pred[:-fcastperiods-2]))\n",
    "                    TESData[i] = pred[-fcastperiods:].tolist()\n",
    "                else:\n",
    "                    TESFcastPerf[i] = np.nan\n",
    "                    TESData[i] = np.nan       \n",
    "            except:\n",
    "                TESFcastPerf[i] = np.nan\n",
    "                TESData[i] = np.nan   \n",
    "        return TESFcastPerf, TESData\n",
    "    tesfcast(data)\n",
    "    \n",
    "    \"Compare and select the best model for each product\"\n",
    "    FcastPerf = pd.concat([ArimaFcastPerf,SESFcastPerf,DESFcastPerf,TESFcastPerf]).set_index('Models')\n",
    "    Model = pd.DataFrame() # Find best model for each product\n",
    "    for i in FcastPerf.columns:\n",
    "        Model[i] = list([FcastPerf.loc[FcastPerf[i] == FcastPerf[i].min()].index[0]])\n",
    "\n",
    "\n",
    "    model_dict = {} # Filter list of products per model\n",
    "    model_list = ['Arima', 'SES', 'DES', 'TES']\n",
    "    for i in model_list:\n",
    "        model_dict[i] = []\n",
    "\n",
    "    for i in Model.columns:\n",
    "        for j in model_list:\n",
    "            if any(Model[i] == j):\n",
    "                model_dict[j].append(i)\n",
    "\n",
    "    AllForecast = pd.concat([ArimaData, SESData, DESData, TESData]) # Extract forecast\n",
    "    FinalForecast = pd.DataFrame({'Period': full_period})\n",
    "\n",
    "    for i in model_list:\n",
    "        for j in model_dict[i]:\n",
    "            FinalForecast[j] = AllForecast.loc[AllForecast['Model'] == i][j]\n",
    "    FinalForecast = FinalForecast[sorted(FinalForecast)]\n",
    "    \n",
    "    return FinalForecast, stopped_products_list, new_products_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Read data\n",
    "data = pd.read_csv(\"Historical Product Demand.csv\")\n",
    "fcastperiods = 6 #forecast user to input this number\n",
    "FinalForecast, stopped_products_list, new_products_list = forecast_run(data,fcastperiods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Product_0002</th>\n",
       "      <th>Product_0138</th>\n",
       "      <th>Product_0597</th>\n",
       "      <th>Product_0875</th>\n",
       "      <th>Product_2066</th>\n",
       "      <th>Product_2091</th>\n",
       "      <th>Product_2127</th>\n",
       "      <th>Product_2165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>3861.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>2547.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-08</td>\n",
       "      <td>138027.0</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Period  Product_0002  Product_0138  Product_0597  Product_0875  \\\n",
       "0  2017-03      138027.0        3861.0           3.0         204.0   \n",
       "1  2017-04      138027.0        2063.0           3.0         204.0   \n",
       "2  2017-05      138027.0        1894.0           3.0         204.0   \n",
       "3  2017-06      138027.0        2547.0           3.0         204.0   \n",
       "4  2017-07      138027.0        1725.0           3.0         204.0   \n",
       "5  2017-08      138027.0        3181.0           3.0         204.0   \n",
       "\n",
       "   Product_2066  Product_2091  Product_2127  Product_2165  \n",
       "0          19.0          94.0         182.0          98.0  \n",
       "1          19.0          94.0         182.0          98.0  \n",
       "2          19.0          94.0         182.0          98.0  \n",
       "3          19.0          94.0         182.0          98.0  \n",
       "4          19.0          94.0         182.0          98.0  \n",
       "5          19.0          94.0         182.0          98.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopped_products_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_products_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
